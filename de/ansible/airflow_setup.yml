- name: a play that runs entirely on the ansible host
  hosts: 127.0.0.1
  connection: local
  vars:
    local_ansible_dir: /Users/lhu/Documents/source_code/ansible
  tasks:
  - name: check out a git repository
    git:
      repo: git@gitlab.feicore.io:DataEngineering/de-datapipeline.git
      #repo: git://gitlab.feicore.io:DataEngineering/de-datapipeline.git
      dest: "{{ local_ansible_dir }}/git_download/workspace/de-datapipeline"
      update: no
    tags: gitlab
######## Upgrade OS and install required python packages
- hosts: master:workers
  remote_user: etluser
  become: yes
  become_user: etluser
  become_method: sudo
  gather_facts: yes
  vars:
    remote_home: /home/etluser
    local_ansible_dir: /Users/lhu/Documents/source_code/ansible
  tasks:
  - name: test which user I am
    shell: whoami
    register: hello
  - debug: msg="{{ hello.stdout }}"
  - name: Update and upgrade apt.
    become_user: root
    apt: update_cache=yes upgrade=dist cache_valid_time=1 force=yes
  - name: I have to run this so that python --version shows python 3.5 not python2.
    become_user: root
    command: update-alternatives --install /usr/bin/python python /usr/bin/python3.5 1 #TBD: should I make sure it run only once?
  - name: Install python3-pip
    become_user: root
    apt: name=python3-pip state=installed
  - name: Upgrade pip so that pip becomes 9.0.1
    pip:
      name: pip
      extra_args: --upgrade
  - name: I run this so that pip --version shows 9.0.1 not 8.X.X.
    become_user: root
    command: update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1 #TBD: should I make sure it run only once?
  - name: test pip --version
    shell: pip --version
    register: hello
  - debug: msg="{{ hello.stdout }}"
  - name: test python --version
    shell: python --version
    register: hello
  - debug: msg="{{ hello.stdout }}"
  - name: Install unixodbc-dev
    become_user: root
    apt: name=unixodbc-dev state=installed
  - name: install pyodbc, pandas, boto3, awscli, flask-bcrypt, flower using pip
    become_user: root
    pip:
      name: "{{ item }}"
      state: present
    with_items:
    - pyodbc
    - psycopg2
    - pandas
    - boto3
    - awscli
    - flask-bcrypt
    - flower #TBD
######## install Airflow
  - name: install airflow[s3, celery]
    become_user: root
    pip:
      name: "{{ item }}"
      state: present
    with_items:
      - airflow
      - s3
      - celery
  - name:
    command: airflow initdb
  - name: Clean artifact path
    file:
      state: absent
      path: "{{ remote_home }}/airflow/airflow.db"
######### Setting up RabbitMQ: master only
- hosts: master
  remote_user: etluser
  become: yes
  become_user: etluser
  become_method: sudo
  gather_facts: no
#  vars_prompt:
#  - name: "rds_pw"
#    prompt: "what is rds password for rds_user=etluser?"
#  - name: "rabbitmq_pw"
#    prompt: "what is rabbitmq password for rabbitmq_user=etluser?"
  vars_files:
  - vars/airflow_cfg_vars.yml

  tasks:
  - name: download erlang-solutions_1.0_all.deb
    become_user: root
    get_url: url=https://packages.erlang-solutions.com/erlang-solutions_1.0_all.deb dest=/tmp
  - name: install deb
    become_user: root
    apt:
      deb: /tmp/erlang-solutions_1.0_all.deb
  - name: Update apt if needed.
    become_user: root
    apt: update_cache=yes upgrade=dist cache_valid_time=3600
  - name: install erlang, erlong-nox
    become_user: root
    apt:
      name: "{{ item }}"
      state: installed
    with_items:
    - erlang
    - erlang-nox
  - name: ensure rabbitmq.list exists
    become_user: root
    copy:
      content: ""
      dest: /etc/apt/sources.list.d/rabbitmq.list
      force: no
  - name: append the line to rabbitmq.list if that line does not exist
    become_user: root
    lineinfile:
      path: /etc/apt/sources.list.d/rabbitmq.list
      line: 'deb http://www.rabbitmq.com/debian/ testing main'
  - name: wget -O- https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | sudo apt-key add -
    become_user: root
    apt_key:
      url: https://www.rabbitmq.com/rabbitmq-release-signing-key.asc
      state: present
  - name: test if rabbitmq apt-key is added
    shell: apt-key list |grep RabbitMQ
    register: hello
  - debug: msg="{{ hello.stdout }}"
  - name: Update and upgrade apt if needed.
    become_user: root
    apt: update_cache=yes upgrade=dist cache_valid_time=3600
  - name: install rabbitmq-server
    become_user: root
    apt: name=rabbitmq-server state=installed
  - name: add rabbitmq users
    become_user: root
    rabbitmq_user: user="{{ rabbitmq_user }}" password="{{ rabbitmq_pw }}" tags=administrator,"{{ rabbitmq_user }}" vhost=/ configure_priv=.* write_priv=.* read_priv=.* state=present
  - name: Enables the rabbitmq_management plugin
    become_user: root
    rabbitmq_plugin:
      names: rabbitmq_management
      state: enabled

- hosts: master:workers
  remote_user: etluser
  become: yes
  become_user: etluser
  become_method: sudo
  gather_facts: no
  vars:
    remote_home: /home/etluser
    local_ansible_dir: /Users/lhu/Documents/source_code/ansible
  vars_files: 
  - vars/airflow_cfg_vars.yml

  tasks:
  - name: modify parameters of remote airflow.cfg
    template: src=files/airflow.cfg.j2 dest={{ remote_home }}/airflow/airflow.cfg owner=etluser group=etluser mode=664
- hosts: master
  remote_user: etluser
  become: yes
  become_user: etluser
  become_method: sudo
  gather_facts: no
  tasks:
  - name: install postgresql-client
    become_user: root
    apt: name=postgresql-client state=installed
  - name: airflow initdb
    command: airflow initdb
- hosts: master:workers
  remote_user: etluser
  become: yes
  become_user: etluser
  become_method: sudo
  gather_facts: no
  vars:
    remote_home: /home/etluser
    local_ansible_dir: /Users/lhu/Documents/source_code/ansible
  tasks:
  - name: Creates directory dags
    file: path="{{ remote_home }}/airflow/dags" state=directory
  - name: Creates directory logs
    file: path="{{ remote_home }}/airflow/logs" state=directory
  - name: Creates directory run
    file: path="{{ remote_home }}/airflow/run" state=directory mode=0777
  - name: copy from local directory to remote
    copy:
      src: "{{ local_ansible_dir }}/git_download/workspace/de-datapipeline/Airflow/dags/"
      dest: "{{ remote_home }}/airflow/dags/"
      force: no
  - name: Creates directory /mnt/etl
    become_user: root
    file: path=/mnt/etl state=directory
  - name: Creates directory /mnt/etl/data
    become_user: root
    file: path=/mnt/etl/data state=directory
  - name: Creates directory /mnt/etl/tmp
    become_user: root
    file: path=/mnt/etl/tmp state=directory
  - name: Microsoft SQL Server  ODBC driver
    become_user: root
    become: yes
    apt_key:
      url: https://packages.microsoft.com/keys/microsoft.asc
      state: present
  - name: test if rabbitmq apt-key is added
    shell: apt-key list |grep Microsoft
    register: hello
  - debug: msg="{{ hello.stdout }}"
  - name: download mssql-release.list
    become_user: root
    get_url: url=https://packages.microsoft.com/config/ubuntu/16.04/prod.list dest=/etc/apt/sources.list.d/mssql-release.list
  - name: Upgrade apt  if needed.
    become_user: root
    apt: update_cache=yes upgrade=dist cache_valid_time=3600
  - name: Install SQL Server prerequisites
    become_user: root
    apt:
      name: "{{item}}"
      state: present
      update_cache: yes
    with_items:
      - msodbcsql
      - mssql-tools
    environment:
      ACCEPT_EULA: Y
  - name: ensure .bash_profile exists
    copy:
      content: ""
      dest: "{{ remote_home }}/.bash_profile"
      force: no
  - name: ensure .bashrc exists
    copy:
      content: ""
      dest: "{{ remote_home }}/.bashrc"
      force: no
  - name: append a line to .bash_profile if the line does not exist
    lineinfile:
      path: "{{ remote_home }}/.bash_profile"
      line: 'export PATH="$PATH:/opt/mssql-tools/bin"'
  - name: add a line to .bash_rc if the line does not exist
    lineinfile:
      path: "{{ remote_home }}/.bashrc"
      line: 'export PATH="$PATH:/opt/mssql-tools/bin"'
  - name: source "{{ remote_home }}/.bashrc"
    shell: . "{{ remote_home }}/.bashrc"
  - name: Creates directory /etc/systemd/system if not exist (should already be there)
    file: path=/etc/systemd/system state=directory
######### Setting up Systemd to Run Airflow: both master and workers
  - name: copy airflow files from local git_download to remote /etc/systemd/system
    become_user: root 
    copy:
      src: "{{ item }}"
      dest: /etc/systemd/system
      force: no
    with_fileglob: #this line is a part of task, not copy module, pay attention to the indention
      - "{{ local_ansible_dir }}/git_download/workspace/de-datapipeline/Airflow/airflow-*.service"
  - name: Creates directory /etc/sysconfig if not exist (should be new)
    become_user: root 
    file: path=/etc/sysconfig state=directory
  - name: copy airflow files from source to remote /etc/sysconfig
    become_user: root 
    copy: #copy airflow (it is a file) to /etc/sysconfig (it is a directory)
      src: "{{ local_ansible_dir }}/git_download/workspace/de-datapipeline/Airflow/airflow"
      dest: /etc/sysconfig/
      force: no
######### Setting up Airflow Services to Run on Machine Startup
- hosts: master
  remote_user: etluser
  become_user: etluser
  become: yes
  gather_facts: no
  tasks:
  - name: systemctl enable airflow-webserver.service airflow-scheduler.service,airflow-flower.service
    become_user: root
    systemd:
      name: "{{ item }}"
      enabled: yes
    with_items:
    - 'airflow-webserver.service'
    - 'airflow-scheduler.service'
    - 'airflow-flower.service'
  - name: start service airflow-webserver and service airflow-flower
    become_user: root
    service:
      name: "{{ item }}"
      state: started
    with_items:
    - 'airflow-webserver'
    - 'airflow-flower'
- hosts: workers
  remote_user: etluser
  become_user: etluser
  become: yes
  gather_facts: no
  tasks:
  - name: systemctl enable airflow-worker.service
    become_user: root
    systemd:
      name: airflow-worker.service
      enabled: yes
  - name: start service airflow-worker
    become_user: root
    service:
      name: airflow-worker
      state: started
