- name: a play that runs entirely on the ansible host
  hosts: 127.0.0.1
  connection: local
  tasks:
  - name: check out a git repository
    git:
      repo: git@gitlab.feicore.io:DataEngineering/de-datapipeline.git
      dest: "{{ git_checkout_dir }}"
      update: no
      version: "{{ git_commit_version }}"
    tags: gitlab
######## Upgrade OS and install required python packages
- hosts: master:workers
  remote_user: etluser
  become: yes
  become_user: etluser
#  become_method: sudo
  gather_facts: yes # get ansible_host in etc-hosts-setup
  roles:
    - etc-hosts-setup # root
    - python3-pip-setup # root
    - python-depended-tools-setup # root
    - airflow-setup #root
    - ssm-agent-setup #root
######### Setting up RabbitMQ: master only
- hosts: master
  remote_user: etluser
  become: yes
  become_user: etluser 
  become_method: sudo
  gather_facts: no
  vars_files:
  - group_vars/airflow_cfg_vars.yml

  roles: 
    - rabbitmq-setup #root
  
- hosts: master:workers
  remote_user: etluser
  become: yes
  become_user: etluser
  become_method: sudo
  gather_facts: no
  vars_files:
  - group_vars/airflow_cfg_vars.yml

  tasks:
  - name: modify parameters of remote airflow.cfg
    template: src="{{ git_checkout_dir }}/Airflow/airflow.cfg.j2" dest={{ remote_home }}/airflow/airflow.cfg owner=etluser group=etluser mode=664

- hosts: master
  remote_user: etluser
  become: yes
  become_user: etluser
  become_method: sudo
  gather_facts: no
  tasks:
  - name: install postgresql-client
    become_user: root
    apt: name=postgresql-client state=installed
  - name: airflow initdb
    command: airflow initdb

- hosts: master:workers
  remote_user: etluser
  become: yes
  become_user: etluser
  become_method: sudo
  gather_facts: no
  vars_files:
  - group_vars/airflow_cfg_vars.yml
  pre_tasks:
  - name: Creates directory dags
    file: path="{{ remote_home }}/airflow/dags" state=directory
  - name: Creates directory logs
    file: path="{{ remote_home }}/airflow/logs" state=directory
  - name: Creates directory run
    file: path="{{ remote_home }}/airflow/run" state=directory mode=0777
  - name: Creates directory /mnt/etl
    file: path=/mnt/etl state=directory
  - name: Creates directory /mnt/etl/data
    file: path=/mnt/etl/data state=directory mode=0755
  - name: Creates directory /mnt/etl/bin
    file: path=/mnt/etl/bin state=directory mode=0755
  - name: Creates directory /mnt/etl/xforms
    file: path=/mnt/etl/xforms state=directory mode=0755
  - name: Creates directory /mnt/etl/tmp
    file: path=/mnt/etl/tmp state=directory mode=0755
  # if become_user is already etluser, then do not need below because the owner and group are already etluser. I just put it here in case 
  - name: change ownership of /mnt/etl if not
    become_user: root
    file: path=/mnt/etl owner=etluser group=etluser mode=0755
  - name: change ownership of /mnt/etl/data if not
    file: path=/mnt/etl/data owner=etluser group=etluser mode=0755
    become_user: root
  - name: change ownership of /mnt/etl/bin if not
    file: path=/mnt/etl/bin owner=etluser group=etluser mode=0755
    become_user: root
  - name: change ownership of /mnt/xforms if not
    file: path=/mnt/etl/xforms owner=etluser group=etluser mode=0755
    become_user: root
  - name: change ownership of /mnt/etl/tmp if not
    file: path=/mnt/etl/tmp owner=etluser group=etluser mode=0755
    become_user: root
  roles: 
    - microsoft-odbc-driver-setup
######### Setting up Systemd to Run Airflow: both master and workers
  tasks:
  - name: Creates directory /etc/systemd/system if not exist (should already be there)
    file: path=/etc/systemd/system state=directory
  - name: copy airflow files from local git_checkout_dir to remote /etc/systemd/system
    become_user: root 
    copy:
      src: "{{ item }}"
      dest: /etc/systemd/system
      force: no
    with_fileglob: #this line is a part of task, not copy module, pay attention to the indention
      - "{{ git_checkout_dir }}/Airflow/airflow-*.service"
  - name: Creates directory /etc/sysconfig if not exist (should be new)
    become_user: root 
    file: path=/etc/sysconfig state=directory
  - name: modify parameters of remote env-properties
    become_user: root
    template: src="{{ git_checkout_dir }}/Airflow/env.properties.j2" dest=/etc/sysconfig/env.properties owner=root group=root mode=664
  - name: Creates directory /mnt/etl/config if not exist (should be new)
    become_user: root
    file: path=/mnt/etl/config state=directory
  - name: modify parameters of remote etl.cfg
    become_user: root
    template: src="{{ git_checkout_dir }}/config/etl.cfg.j2" dest=/mnt/etl/config/etl.cfg owner=root group=root mode=664

######### Setting up Airflow Services to Run on Machine Startup
- hosts: master
  remote_user: etluser
  become_user: etluser
  become: yes
  gather_facts: no
  tags: service 
  roles:
    - airflow-master-enable

- hosts: workers
  remote_user: etluser
  become_user: etluser
  become: yes
  gather_facts: no
  roles:
    - airflow-workers-enable

- hosts: master
  remote_user: etluser
  become: yes
  become_user: root
  gather_facts: yes
  tags: nginx
  vars_files:
  - group_vars/airflow_cfg_vars.yml
  vars:
    nginx_vhosts:
      - listen: "80"
        server_name: "airflow.{{ domain_name }}"
        state: "present"
        extra_parameters: |
          location / {
            proxy_pass_header Authorization;
            proxy_pass http://localhost:8080;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto https;
            proxy_http_version 1.1;
            proxy_redirect off;
            proxy_set_header Connection "";
            proxy_buffering off;
            client_max_body_size 0;
            proxy_read_timeout 36000s;
          }
  roles:
    - geerlingguy.nginx
